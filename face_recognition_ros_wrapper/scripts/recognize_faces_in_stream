#!/usr/bin/env python

import rospy
import sys
import cv2
import face_recognition
import pickle
from cv_bridge import CvBridge, CvBridgeError

from std_msgs.msg import String
from sensor_msgs.msg import Image


class face_recognizer:
    def __init__(self):

        self.locations = None

        self.pub = rospy.Publisher('recognized_faces', String, queue_size=10)
        self.pub1 = rospy.Publisher('face_locations_approx', String, queue_size=10)
        self.sub = rospy.Subscriber(
            rospy.get_param(rospy.resolve_name("~video_stream_topic")), 
            Image, 
            self.recognize_faces_callback)

        # self.sub = rospy.Subscriber(
        #     rospy.get_param(rospy.resolve_name("~depth_stream_topic")), 
        #     Image, 
        #     self.recognize_depth_callback)

        self.encodings_data = self.init_encodings_dict()

        self.bridge = CvBridge()

    def init_encodings_dict(self):
        face_encodings_file = rospy.get_param("face_encodings_location")    
        encodings_data = pickle.loads(open(face_encodings_file, "rb").read())

        return encodings_data

    def recognize_faces_callback(self, data):
        cv_image = self.convert_image(data)
        name = self.get_face_match(cv_image)

        if name is not None:
            self.pub.publish(name)

    def recognize_depth_callback(self, data):
        cv_image = self.convert_depth(data)
        name = self.get_face_depth(cv_image)

        if name is not None:
            self.pub1.publish(name)

    def convert_image(self, data):
        try:
            return self.bridge.imgmsg_to_cv2(data, "rgb8")
        except CvBridgeError as e:
            print(e)

    def convert_depth(self, data):
        try:
            return self.bridge.imgmsg_to_cv2(data, "mono8")
        except CvBridgeError as e:
            print(e)

    def get_face_match(self, cv_image):
        boxes = face_recognition.face_locations(cv_image, model='hog')

        self.locations = list()

        if not boxes:
            return None
        else:
            encodings = face_recognition.face_encodings(cv_image, boxes)
        names = ""
        for encoding, location in zip(encodings, boxes):
            matches = face_recognition.compare_faces(self.encodings_data["encodings"], encoding)
            if True in matches:
                matchedIdxs = [i for (i, b) in enumerate(matches) if b]
                counts = {}

                for i in matchedIdxs:
                    name = self.encodings_data["names"][i]
                    counts[name] = counts.get(name, 0) + 1

                name = max(counts, key=counts.get)
                self.locations.append((name, location))
                names += name + ','
        if len(names) == 0:
            return None
        else:
            return names[:-1]

    def get_face_depth(self, cv_image):
        name_locs = ""
        if self.locations is None or len(self.locations) == 0:
            return None
        else:
            for name, locs in self.locations:
                name_locs += f'{name} - {locs},'
            return name_locs
            

def main(args):
    try:
        rospy.init_node('stream_face_recognizer')

        face_recognizer_object = face_recognizer()
        print("Ready to recognize faces in video stream")

        rospy.spin()

    except rospy.ROSInterruptException as e:
        print(e)


if __name__ == "__main__":
    main(sys.argv)